{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h3\n",
    "import json\n",
    "import folium\n",
    "from geojson.feature import *\n",
    "import streamlit as st\n",
    "import branca.colormap as cm \n",
    "import folium\n",
    "from streamlit_folium import folium_static\n",
    "from folium import Map, Marker, GeoJson \n",
    "\n",
    "\n",
    "gdf = gpd.read_file('../data/kontur_population_KE_20231101.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_info(df, df_name):\n",
    "    print(f\"Data Structure for {df_name}\")\n",
    "    print(\"-\"*10)\n",
    "    print(f\"Dimensions: {df.shape}\")\n",
    "    print(f\"Data Types:\\n{df.dtypes}\")\n",
    "    print(f\"Missing Values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Unique observations:\\n{df.nunique()}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging population data and the age demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = pd.read_csv(\"./output/KEN_agesex_aggregated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pop_total_and_sum(df):\n",
    "    total_pop = df['total_population'].round().astype(int)\n",
    "    sum_gender = (df['total_male'].round().astype(int) + df['total_female'].round().astype(int))\n",
    "\n",
    "    # Count the number of rows where they match\n",
    "    matching_rows = (total_pop == sum_gender).sum()\n",
    "    return total_pop, sum_gender, matching_rows\n",
    "\n",
    "def process_population_data(df):\n",
    "    \"\"\"\n",
    "    Process population data by:\n",
    "    1. Filling missing population values with sum of demographic columns\n",
    "    2. Creating total male and female population columns\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing population data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Processed DataFrame with new columns\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Get all demographic columns (excluding 'h3', 'population', and 'geometry')\n",
    "    demographic_cols = [col for col in df.columns \n",
    "                       if col.startswith('population_') \n",
    "                       and col != 'population']\n",
    "    \n",
    "    # Fill missing population values with sum of demographic columns\n",
    "    processed_df['population'] = processed_df['population'].fillna(\n",
    "        processed_df[demographic_cols].sum(axis=1)\n",
    "    )\n",
    "    \n",
    "    # Create total male population column\n",
    "    male_cols = [col for col in df.columns if col.startswith('population_m')]\n",
    "    processed_df['total_male'] = processed_df[male_cols].sum(axis=1).round().astype(int)\n",
    "    \n",
    "    # Create total female population column\n",
    "    female_cols = [col for col in df.columns if col.startswith('population_f')]\n",
    "    processed_df['total_female'] = processed_df[female_cols].sum(axis=1).round().astype(int)\n",
    "\n",
    "    processed_df.rename(columns={'population': 'total_population'}, inplace=True)\n",
    "    processed_df.drop('geometry', axis=1, inplace=True)\n",
    "\n",
    "    total_pop, sum_gender, matching_rows = get_pop_total_and_sum(processed_df)\n",
    "\n",
    "    print(f\"Number of rows where total population equals sum of gender totals: {matching_rows}\")\n",
    "\n",
    "    # negative value indicates that the sum is bigger than the recorded total pop from first dataset \n",
    "    # positive value indicates that the recorded total pop from first dataset is bigger than the sum\n",
    "    processed_df['recorded_pop_diff'] = total_pop - sum_gender\n",
    "\n",
    "    #Update the total_population to capture the max number of population \n",
    "    # Do this before update to keep the original difference recorded\n",
    "    # Create the condition where sum is bigger than total population\n",
    "    condition = (processed_df['total_male'] + processed_df['total_female']) > processed_df['total_population']\n",
    "\n",
    "    # Replace population where condition is True\n",
    "    processed_df.loc[condition, 'total_population'] = processed_df.loc[condition, 'total_male'] + processed_df.loc[condition, 'total_female']\n",
    "    total_pop, sum_gender, matching_rows = get_pop_total_and_sum(processed_df)\n",
    "    print(f\"Number of rows where total population equals sum of gender totals after update: {matching_rows}\")\n",
    "\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.to_crs(epsg=4326)\n",
    "df_merged = df_demographics.merge(gdf, on='h3', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where total population equals sum of gender totals: 40548\n",
      "Number of rows where total population equals sum of gender totals after update: 143855\n"
     ]
    }
   ],
   "source": [
    "df_merged_clean = process_population_data(df_merged)\n",
    "def get_h3_center(h3_index):\n",
    "    # h3.h3_to_geo returns (lat, lng)\n",
    "    lat, lng = h3.h3_to_geo(h3_index)\n",
    "    return pd.Series({'latitude': lat, 'longitude': lng})\n",
    "\n",
    "# Apply the function to create new columns\n",
    "df_merged_clean[['latitude', 'longitude']] = df_merged_clean['h3'].apply(get_h3_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h3', 'population_m10', 'population_f45', 'population_f50',\n",
       "       'population_f40', 'population_f55', 'population_f80', 'population_m15',\n",
       "       'population_f25', 'population_f30', 'population_m65', 'population_m70',\n",
       "       'population_m60', 'population_m75', 'population_f20', 'population_f35',\n",
       "       'population_f10', 'population_m1', 'population_m50', 'population_m45',\n",
       "       'population_m0', 'population_m55', 'population_m40', 'population_m5',\n",
       "       'population_f15', 'population_m80', 'population_m30', 'population_m25',\n",
       "       'population_f5', 'population_f70', 'population_f65', 'population_f0',\n",
       "       'population_f75', 'population_f60', 'population_f1', 'population_m35',\n",
       "       'population_m20', 'total_population', 'total_male', 'total_female',\n",
       "       'recorded_pop_diff', 'latitude', 'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "print(f\"Minimum: {df_merged_clean['recorded_pop_diff'].min()}\")\n",
    "print(f\"Maximum: {df_merged_clean['recorded_pop_diff'].max()}\")\n",
    "print(f\"Mean: {df_merged_clean['recorded_pop_diff'].mean():.2f}\")\n",
    "print(f\"Median: {df_merged_clean['recorded_pop_diff'].median()}\")\n",
    "print(f\"Mode: {df_merged_clean['recorded_pop_diff'].mode()[0]}\")  # [0] because mode can return multiple values\n",
    "print(f\"Standard Deviation: {df_merged_clean['recorded_pop_diff'].std():.2f}\")\n",
    "\n",
    "# Get quartile information\n",
    "print(\"\\nQuartile Information:\")\n",
    "print(df_merged_clean['recorded_pop_diff'].describe())\n",
    "\n",
    "# Count the frequency of each unique value\n",
    "print(\"\\nValue Counts:\")\n",
    "print(df_merged_clean['recorded_pop_diff'].value_counts().sort_index())\n",
    "\n",
    "# Optional: Create a histogram to visualize the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df_merged_clean, x='recorded_pop_diff', bins=30)\n",
    "plt.title('Distribution of Differences between Total Population and Sum of Genders')\n",
    "plt.xlabel('Difference')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Optional: Add a box plot to see outliers\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(x=df_merged_clean['recorded_pop_diff'])\n",
    "plt.title('Box Plot of Differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poverty data County (doing merge with h3 population here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_counties = gpd.read_file('../data/ken_adm_iebc_20191031_shp/ken_admbnda_adm2_iebc_20191031.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_counties[sub_counties['ADM1_EN'] == 'Mombasa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_counties['ADM2_EN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Read the shapefile\n",
    "counties = gpd.read_file('../data/ken_adm_iebc_20191031_shp/ken_admbnda_adm1_iebc_20191031.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_from_coordinates(df, counties):\n",
    "    geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
    "    h3_gdf = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "    # 2. Perform spatial join\n",
    "    # This will add all columns from counties to your H3 data\n",
    "    result = gpd.sjoin(h3_gdf, counties, how='left', predicate='within')\n",
    "\n",
    "    # 3. If you only want to keep the county name (assuming it's in 'ADM1_EN')\n",
    "    # Keep only the original columns plus the county name\n",
    "    original_columns = list(df.columns)\n",
    "    df['county'] = result['ADM1_EN']\n",
    "\n",
    "    # 4. Some hexagons are left unmatched so perform other operations to match them with a county\n",
    "    unmatched_hexagons = df[df['county'].isna()].copy()\n",
    "    geometry = [Point(xy) for xy in zip(unmatched_hexagons['longitude'], unmatched_hexagons['latitude'])]\n",
    "    h3_gdf = gpd.GeoDataFrame(unmatched_hexagons, geometry=geometry, crs='EPSG:4326')\n",
    "    intersect_match = gpd.sjoin(h3_gdf, counties, how='left', predicate='intersects')\n",
    "\n",
    "\n",
    "    def assign_nearest_county(point, counties_gdf):\n",
    "        # Calculate distance to all counties\n",
    "        distances = counties_gdf.geometry.distance(point.geometry)\n",
    "        # Get the county with minimum distance\n",
    "        nearest_county = counties_gdf.iloc[distances.argmin()]\n",
    "        return nearest_county['ADM1_EN']\n",
    "\n",
    "    # For any hexagons still unmatched after intersects, find nearest county\n",
    "    still_unmatched = intersect_match[intersect_match['ADM1_EN'].isna()]\n",
    "    if len(still_unmatched) > 0:\n",
    "        still_unmatched['nearest_county'] = still_unmatched.apply(\n",
    "            lambda x: assign_nearest_county(x, counties), axis=1\n",
    "        )\n",
    "\n",
    "\n",
    "    df.loc[still_unmatched.index, 'county'] = still_unmatched['nearest_county']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/1926180795.py:23: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  distances = counties_gdf.geometry.distance(point.geometry)\n"
     ]
    }
   ],
   "source": [
    "h3_df_county = get_county_from_coordinates(df_merged_clean.copy(), counties.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df = pd.read_csv('../data/KEN_MPI_COUNTY_PROCESSED.csv')\n",
    "poverty_df = poverty_df.rename(columns={'Subnational region': 'county'})\n",
    "poverty_df.drop(['Country', 'ISO country numeric code', 'ISO country code','World region'], axis=1, inplace=True)\n",
    "h3_with_poverty = h3_df_county.merge(poverty_df, \n",
    "                             on='county', \n",
    "                             how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Services Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_services = gpd.read_file('../data/ken_financial_services_polygons/ken_financial_services_polygons.gpkg')\n",
    "financial_services_points = gpd.read_file('../data/ken_financial_services_points/ken_financial_services_points.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_services.drop(['name:en', 'operator', 'network', 'addr:full', 'addr:city', 'source', 'name:sw'], axis=1, inplace=True)\n",
    "financial_services_points.drop(['name:en', 'operator', 'network', 'addr:full', 'addr:city', 'source', 'name:sw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structure for financial_services_points\n",
      "----------\n",
      "Dimensions: (1720, 7)\n",
      "Data Types:\n",
      "name           object\n",
      "amenity        object\n",
      "osm_id          int64\n",
      "osm_type       object\n",
      "geometry     geometry\n",
      "longitude     float64\n",
      "latitude      float64\n",
      "dtype: object\n",
      "Missing Values:\n",
      "name         227\n",
      "amenity        0\n",
      "osm_id         0\n",
      "osm_type       0\n",
      "geometry       0\n",
      "longitude      0\n",
      "latitude       0\n",
      "dtype: int64\n",
      "Unique observations:\n",
      "name          505\n",
      "amenity         7\n",
      "osm_id       1720\n",
      "osm_type        1\n",
      "geometry     1719\n",
      "longitude    1717\n",
      "latitude     1713\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_df_info(financial_services_points, 'financial_services_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_services_points['amenity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates_fin_services(gdf):\n",
    "    \"\"\"\n",
    "    Extract longitude and latitude from geometry column of a GeoDataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): Input GeoDataFrame with geometry column\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame: Original GeoDataFrame with new longitude and latitude columns\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    gdf = gdf.copy()\n",
    "    \n",
    "    # Extract coordinates\n",
    "    gdf['longitude'] = gdf.geometry.centroid.x\n",
    "    gdf['latitude'] = gdf.geometry.centroid.y\n",
    "    \n",
    "    # Verify the results\n",
    "    print(\"Number of points processed:\", len(gdf))\n",
    "    print(\"Number of missing coordinates:\", gdf[['longitude', 'latitude']].isna().any(axis=1).sum())\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 1720\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/649738154.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/649738154.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "financial_services_points = extract_coordinates_fin_services(financial_services_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time\n",
    "\n",
    "def lookup_places_osm(df):\n",
    "    \"\"\"\n",
    "    Look up place names using OpenStreetMap's Nominatim for coordinates with missing names.\n",
    "    \"\"\"\n",
    "    # Initialize geocoder\n",
    "    geolocator = Nominatim(user_agent=\"ken_financial_services_points_app\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    count = 0\n",
    "    count_null_names_before = df['name'].isna().sum()\n",
    "    print('[INFO] Attempting to fill out the null names in the financial services...')\n",
    "    for idx in df[df['name'].isna()].index:\n",
    "        lat = df.loc[idx, 'latitude']\n",
    "        lng = df.loc[idx, 'longitude']\n",
    "        \n",
    "        try:\n",
    "            # Reverse geocode the coordinates\n",
    "            location = geolocator.reverse(f\"{lat}, {lng}\", exactly_one=True)\n",
    "            \n",
    "            if location:\n",
    "                # Extract the name from address data\n",
    "                address = location.raw.get('address', {})\n",
    "                print(f\"Address extracted = {address}\")\n",
    "                if 'amenity' in address:\n",
    "                    print(f'[INFO] Amenity Name found!\\n')\n",
    "                    df.loc[idx, 'name'] = address['amenity']\n",
    "            \n",
    "            # Sleep to respect rate limits\n",
    "            time.sleep(1)  # OpenStreetMap requires slower rates\n",
    "            \n",
    "            count += 1\n",
    "            if count % 5 == 0:\n",
    "                print(f\"Processed {count} locations\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing coordinates ({lat}, {lng}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    count_null_names_after = df['name'].isna().sum()\n",
    "    print(f\"Null values in the name column before processing = {count_null_names_before}\")\n",
    "    print(f\"Null values in the name column after processing = {count_null_names_after}\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_amenities = ['bank', 'atm', 'mobile_money_agent', 'bureau_de_change', 'money_transfer', 'sacco']\n",
    "\n",
    "# Filter rows where 'amenity' is in the list\n",
    "financial_services_points_no_office = financial_services_points[financial_services_points['amenity'].isin(financial_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_services_points_no_office['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_services_points_no_office['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_services_points = lookup_places_osm_fin(financial_services_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 131\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/649738154.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/649738154.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "financial_services_with_coords = extract_coordinates_fin_services(financial_services)\n",
    "# Banks or ATMS\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 510542492, 'name'] = 'KCB Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 927298614, 'name'] = 'Sidian Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 694282218, 'name'] = 'National Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 206638774, 'name'] = 'KCB Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 488367319, 'name'] = 'Rafiki Microfinance Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 488598405, 'name'] = 'Tower Sacco Society Limited'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 1092605098, 'name'] = 'Equity Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 927298612, 'name'] = 'Equity Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 927298613, 'name'] = 'Equity Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 1156337156, 'name'] = 'Trans National Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 331976738, 'name'] = 'Kenya Commercial Bank'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 988844673, 'name'] = 'Sanrock mpesa'\n",
    "\n",
    "# Post offices\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 386760599, 'name'] = 'Fargo Courier'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 322160157, 'name'] = 'POSTA'\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 313516167, 'name'] = 'POSTA'\n",
    "\n",
    "# Set name to unknown if google maps has no data about the institution when looking up the coordinates\n",
    "financial_services_with_coords.loc[financial_services_with_coords['osm_id'] == 580833129, 'name'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize bank names\n",
    "def standardize_bank_name(df, pattern, standard_name):\n",
    "    \"\"\"\n",
    "    Standardize bank names based on a pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing bank names\n",
    "    pattern: String pattern to match (e.g., 'KCB')\n",
    "    standard_name: Name to replace matches with (e.g., 'KCB Bank')\n",
    "    \"\"\"\n",
    "    if (type(pattern) == str):\n",
    "        # Show current variations\n",
    "        print(f\"Current variations of names containing '{pattern}':\")\n",
    "        print(df[df['name'].str.contains(pattern, case=False, na=False)]['name'].unique())\n",
    "        \n",
    "        # Standardize the name\n",
    "        df.loc[df['name'].str.contains(pattern, case=False, na=False), 'name'] = standard_name\n",
    "        \n",
    "        # Verify the change\n",
    "        print(f\"\\nAfter standardization - all matched entries now show as '{standard_name}'\")\n",
    "        print(df[df['name'].str.contains(pattern, case=False, na=False)]['name'].unique())\n",
    "    \n",
    "    else:\n",
    "        print(\"Processing multiple patterns at once\")\n",
    "        for pat in pattern:\n",
    "            # Show current variations\n",
    "            print(f\"Current variations of names containing '{pat}':\")\n",
    "            print(df[df['name'].str.contains(pat, case=False, na=False)]['name'].unique())\n",
    "            \n",
    "            # Standardize the name\n",
    "            df.loc[df['name'].str.contains(pat, case=False, na=False), 'name'] = standard_name\n",
    "            \n",
    "            # Verify the change\n",
    "            print(f\"\\nAfter standardization - all matched entries now show as '{standard_name}'\")\n",
    "            print(df[df['name'].str.contains(pat, case=False, na=False)]['name'].unique())\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming banks since a lot of them represent the same bank \n",
    "financial_services_points.loc[financial_services_points['name'] == 'K C B', 'name'] = 'KCB Bank'\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'KCB', 'KCB Bank')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Kenya Commercial Bank', 'KCB Bank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Stanbic', 'Stanbic Bank')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Family Bank', 'Family Bank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Commercial Bank of', 'Commercial Bank of Africa')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Bank of Africa', 'Commercial Bank of Africa')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'NIC Bank Limited', 'Commercial Bank of Africa')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'CBK', 'Cooperative Bank of Kenya') \n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Cooperative Bank', 'Cooperative Bank of Kenya') \n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Co-operative Bank', 'Cooperative Bank of Kenya')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'I&M', 'I&M Bank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Post Bank', 'Kenya Post Office Savings Bank')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Postbank', 'Kenya Post Office Savings Bank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Chase', 'Chase Bank')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'ChaseBank', 'Chase Bank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'KWFT', 'Kenya Women Finance Trust')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Kenya Women Finance Trust', 'Kenya Women Finance Trust')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Trans National Bank', 'Access Bank Kenya')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'National Bank', 'National Bank of Kenya')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Equity', 'Equity Bank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Barclays', 'Barclays Bank')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Barcalys', 'Barclays Bank')\n",
    "\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Co-Op Bank', 'Co-operative Bank of Kenya')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Co-op', 'Co-operative Bank of Kenya')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Co-', 'Co-operative Bank of Kenya')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, ['Co operative', 'Co -', 'Co Op Bank', 'Co Op', 'Coop Bank'], 'Co-operative Bank of Kenya')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Ecobank', 'EcoBank')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Absa', 'Absa Bank')\n",
    "\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'DAIMOND', 'Diamond Trust Bank Group')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'DTB', 'Diamond Trust Bank Group')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Diamond Trust Bank', 'Diamond Trust Bank Group')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'Sacco', 'Savings and Credit Cooperative Organization')\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'M-Pesa', 'M-Pesa Point')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, 'mpesa', 'M-Pesa Point')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, ['Pesa', 'psea'], 'M-Pesa Point')\n",
    "\n",
    "\n",
    "financial_services_points = standardize_bank_name(financial_services_points, ['Kenya Women Finance', 'Kenya Woman Finance'], 'Kenya Women Finance Trust')\n",
    "financial_services_points = standardize_bank_name(financial_services_points, ['Kenya Women Micro', 'Kenya Woman Micro'], 'Kenya Women Microfinance Bank')\n",
    "\n",
    "# Rename all variations to \"Posta\" (post office)\n",
    "financial_services_points.loc[financial_services_points['name'].str.contains('Posta', case=False, na=False), 'name'] = 'POSTA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming banks since a lot of them represent the same bank \n",
    "financial_services_with_coords.loc[financial_services_with_coords['name'] == 'K C B', 'name'] = 'KCB Bank'\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'KCB', 'KCB Bank')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Kenya Commercial Bank', 'KCB Bank')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Stanbic', 'Stanbic Bank')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Family Bank', 'Family Bank')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Commercial Bank of', 'Commercial Bank of Africa')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Bank of Africa', 'Commercial Bank of Africa')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'NIC Bank Limited', 'Commercial Bank of Africa')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'CBK', 'Cooperative Bank of Kenya') \n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Cooperative Bank', 'Cooperative Bank of Kenya') \n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Co-operative Bank', 'Cooperative Bank of Kenya')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'I&M', 'I&M Bank')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Post Bank', 'Kenya Post Office Savings Bank')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'KWFT', 'Kenya Women Finance Trust')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Kenya Women Finance Trust', 'Kenya Women Finance Trust')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Trans National Bank', 'Access Bank Kenya')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'National Bank', 'National Bank of Kenya')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Equity', 'Equity Bank')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Barclays', 'Barclays Bank')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'DAIMOND', 'Diamond Trust Bank Group')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'DTB', 'Diamond Trust Bank Group')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Diamond Trust Bank', 'Diamond Trust Bank Group')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'Sacco', 'Savings and Credit Cooperative Organization')\n",
    "\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'M-Pesa', 'M-Pesa Point')\n",
    "financial_services_with_coords = standardize_bank_name(financial_services_with_coords, 'mpesa', 'M-Pesa Point')\n",
    "\n",
    "# Rename all variations to \"Posta\" (post office)\n",
    "financial_services_with_coords.loc[financial_services_with_coords['name'].str.contains('Posta', case=False, na=False), 'name'] = 'POSTA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health facilities Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_facilities = gpd.read_file('../data/ken_health_facilities_polygons/ken_health_facilities_polygons.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_facilities_points = gpd.read_file('../data/ken_health_facilities_points/ken_health_facilities_points.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_facilities_points['amenity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structure for health_facilities_points\n",
      "----------\n",
      "Dimensions: (1761, 15)\n",
      "Data Types:\n",
      "name                       object\n",
      "name:en                    object\n",
      "amenity                    object\n",
      "building                   object\n",
      "healthcare                 object\n",
      "healthcare:speciality      object\n",
      "operator:type              object\n",
      "capacity:persons           object\n",
      "addr:full                  object\n",
      "addr:city                  object\n",
      "source                     object\n",
      "name:sw                    object\n",
      "osm_id                      int64\n",
      "osm_type                   object\n",
      "geometry                 geometry\n",
      "dtype: object\n",
      "Missing Values:\n",
      "name                       74\n",
      "name:en                  1748\n",
      "amenity                    37\n",
      "building                 1758\n",
      "healthcare               1124\n",
      "healthcare:speciality    1667\n",
      "operator:type            1155\n",
      "capacity:persons         1761\n",
      "addr:full                1760\n",
      "addr:city                1610\n",
      "source                   1612\n",
      "name:sw                  1761\n",
      "osm_id                      0\n",
      "osm_type                    0\n",
      "geometry                    0\n",
      "dtype: int64\n",
      "Unique observations:\n",
      "name                     1537\n",
      "name:en                    13\n",
      "amenity                    11\n",
      "building                    2\n",
      "healthcare                 21\n",
      "healthcare:speciality      33\n",
      "operator:type              19\n",
      "capacity:persons            0\n",
      "addr:full                   1\n",
      "addr:city                  42\n",
      "source                     11\n",
      "name:sw                     0\n",
      "osm_id                   1761\n",
      "osm_type                    1\n",
      "geometry                 1723\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_df_info(health_facilities_points, 'health_facilities_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_facilities.drop(['name:en', 'operator:type', 'capacity:persons', 'addr:full', 'addr:city', 'source', 'name:sw', 'healthcare:speciality'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "healthcare\n",
       "hospital            518\n",
       "clinic               23\n",
       "yes                   7\n",
       "pharmacy              5\n",
       "laboratory            2\n",
       "centre                2\n",
       "doctor                1\n",
       "level_3_hospital      1\n",
       "optometrist           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_facilities['healthcare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates_from_geometry(gdf):\n",
    "    \"\"\"\n",
    "    Extract longitude and latitude from geometry column of a GeoDataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): Input GeoDataFrame with geometry column\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame: Original GeoDataFrame with new longitude and latitude columns\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    gdf = gdf.copy()\n",
    "    \n",
    "    # Extract coordinates\n",
    "    gdf['longitude'] = gdf.geometry.centroid.x\n",
    "    gdf['latitude'] = gdf.geometry.centroid.y\n",
    "    \n",
    "    # Verify the results\n",
    "    print(\"Number of points processed:\", len(gdf))\n",
    "    print(\"Number of missing coordinates:\", gdf[['longitude', 'latitude']].isna().any(axis=1).sum())\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 684\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/2997271296.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/2997271296.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "health_facilities = extract_coordinates_from_geometry(health_facilities)\n",
    "health_facilities.loc[health_facilities['osm_id'] == 792488917, 'amenity'] = 'hospital'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 1166210971, 'amenity'] = 'clinic'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 1126947216, 'amenity'] = 'clinic'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 449705379, 'amenity'] = 'clinic'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 1064641276, 'amenity'] = 'clinic'\n",
    "\n",
    "\n",
    "# Fill out the amenities for entries corresponding to hospitals \n",
    "health_facilities.loc[health_facilities['osm_id'] == 1167183485, 'amenity'] = 'hospital'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 691508967, 'amenity'] = 'hospital'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 656482162, 'amenity'] = 'hospital'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 364992933, 'amenity'] = 'hospital'\n",
    "\n",
    "\n",
    "# Checked website for this one and it says clinic\n",
    "health_facilities.loc[health_facilities['osm_id'] == 798278750, 'amenity'] = 'clinic'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 1064641270, 'amenity'] = 'clinic'\n",
    "\n",
    "# Checked google maps using coordinates \n",
    "health_facilities.loc[health_facilities['osm_id'] == 1170419534, 'amenity'] = 'pharmacy'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 1170410092, 'amenity'] = 'pharmacy'\n",
    "health_facilities.loc[health_facilities['osm_id'] == 1316676525, 'amenity'] = 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_amenities = health_facilities[health_facilities['amenity'].isna()].copy()\n",
    "\n",
    "# Create a format that's easy to copy-paste into Google Maps\n",
    "missing_amenities['google_maps_format'] = missing_amenities['latitude'].astype(str) + ', ' + missing_amenities['longitude'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time\n",
    "\n",
    "def lookup_places_osm(df):\n",
    "    \"\"\"\n",
    "    Look up place names using OpenStreetMap's Nominatim for coordinates with missing names.\n",
    "    \"\"\"\n",
    "    # Initialize geocoder\n",
    "    geolocator = Nominatim(user_agent=\"my_health_facilities_app\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    count = 0\n",
    "    count_null_names_before = df['name'].isna().sum()\n",
    "    for idx in df[df['name'].isna()].index:\n",
    "        lat = df.loc[idx, 'latitude']\n",
    "        lng = df.loc[idx, 'longitude']\n",
    "        \n",
    "        try:\n",
    "            # Reverse geocode the coordinates\n",
    "            location = geolocator.reverse(f\"{lat}, {lng}\", exactly_one=True)\n",
    "            \n",
    "            if location:\n",
    "                # Extract the name from address data\n",
    "                address = location.raw.get('address', {})\n",
    "                print(f\"Address extracted = {address}\")\n",
    "                if 'amenity' in address:\n",
    "                    df.loc[idx, 'name'] = address['amenity']\n",
    "                elif 'healthcare' in address:\n",
    "                    df.loc[idx, 'name'] = address['healthcare']\n",
    "            \n",
    "            # Sleep to respect rate limits\n",
    "            time.sleep(1)  # OpenStreetMap requires slower rates\n",
    "            \n",
    "            count += 1\n",
    "            if count % 5 == 0:\n",
    "                print(f\"Processed {count} locations\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing coordinates ({lat}, {lng}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    count_null_names_after = df['name'].isna().sum()\n",
    "    print(f\"Null values in the name column before processing = {count_null_names_before}\")\n",
    "    print(f\"Null values in the name column after processing = {count_null_names_after}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the OSM version (no API key needed)\n",
    "health_facilities_with_names = lookup_places_osm(health_facilities)\n",
    "health_facilities_with_names.loc[health_facilities_with_names['name'] == 'University of Eldoret' , 'name'] = 'Chepkoilel Sisiwa Dispensary'\n",
    "health_facilities_with_names.loc[health_facilities_with_names['name'] == 'Word Temple Church' , 'name'] = 'Grace Medical Clinic'\n",
    "health_facilities_with_names['name'] = health_facilities_with_names['name'].fillna(health_facilities_with_names['amenity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Railways Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "railways_lines = gpd.read_file('../data/ken_railways_lines/ken_railways_lines.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "railways_lines.drop(['name:en', 'ele', 'operator:type', 'layer', 'addr:full', 'addr:city', 'source', 'name:sw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "railways_lines['name'] = railways_lines['name'].fillna('Name Not Listed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df_info(railways_lines, 'railways_lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_of_interest_points = gpd.read_file('../data/ken_points_of_interest_points/ken_points_of_interest_points.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthcare facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_amenities = ['pharmacy', 'clinic', 'hospital', 'veterinary', 'dispensary', 'dentist', '*', 'nursing_home', 'doctors', 'medical transport service','health_post', 'health_center','health_centre','pharmaccy','traditional health centre','veterinary_pharmacy', 'healthcare','clinic;hospital','health']\n",
    "health_facilities_points = points_of_interest_points[points_of_interest_points['amenity'].isin(health_amenities)]\n",
    "\n",
    "# Drop the rows pertaining to health_facilities\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(health_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_facilities_points.loc[health_facilities_points['amenity'] == 'pharmaccy', 'amenity'] = 'pharmacy'\n",
    "health_facilities_points.loc[health_facilities_points['amenity'] == 'health_centre', 'amenity'] = 'health_center'\n",
    "health_facilities_points.loc[health_facilities_points['amenity'] == 'health', 'amenity'] = 'health_center'\n",
    "health_facilities_points.loc[health_facilities_points['amenity'] == 'healthcare', 'amenity'] = 'health_center'\n",
    "health_facilities_points.loc[health_facilities_points['amenity'] == 'clinic;hospital', 'amenity'] = 'clinic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 1824\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "health_facilities_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "health_facilities_points = extract_coordinates_from_geometry(health_facilities_points)\n",
    "health_facilities_points = lookup_places_osm(health_facilities_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a format that's easy to copy-paste into Google Maps\n",
    "health_facilities_points['google_maps_format'] = health_facilities_points['latitude'].astype(str) + ', ' + health_facilities_points['longitude'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75119"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points_of_interest_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the financial services data from the points of interest data\n",
    "financial_amenities = ['bank', 'atm', 'mobile_money_agent', 'post_office', 'bureau_de_change', 'money_transfer', 'sacco']\n",
    "\n",
    "# Filter rows where 'amenity' is in the list\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(financial_amenities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "educational_amenities = ['school', 'driving_school', 'university', 'library', 'college', 'kindergarten']\n",
    "\n",
    "educational_facilities_points = points_of_interest_points[points_of_interest_points['amenity'].isin(educational_amenities)]\n",
    "\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(educational_amenities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 5196\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "educational_facilities_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "educational_facilities_points = extract_coordinates_from_geometry(educational_facilities_points)\n",
    "educational_facilities_points = lookup_places_osm(educational_facilities_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df_info(educational_facilities_points, 'educational_facilities_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_amenities = ['fixme', 'no', 'Mission']\n",
    "amenity_value_counts = points_of_interest_points['amenity'].value_counts()\n",
    "amenity_values_to_drop = amenity_value_counts[amenity_value_counts == 1].index\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(wrong_amenities)]\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(amenity_values_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportation_amenities = ['bus_station', 'taxi', 'ferry_terminal', 'bus_stop', 'train_station', 'parking', 'bicycle_parking', 'parking_space', 'motorcycle_parking', 'car_rental', 'car_sharing', 'vehicle_inspection', 'bridge', 'ferry_terminal', 'taxi_stand', 'airport', 'harbor', 'railway_station', 'fuel', 'charging_station']\n",
    "\n",
    "transportation_points = points_of_interest_points[points_of_interest_points['amenity'].isin(transportation_amenities)]\n",
    "\n",
    "\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(transportation_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportation_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "transportation_points = extract_coordinates_from_geometry(transportation_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Amenities & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_amenities = ['toilets', 'shower', 'drinking_water', 'fountain', 'waste_disposal', 'waste_transfer_station', 'waste_basket', 'recycling', 'street_lamp', 'telephone', 'clock',  'pond', 'sanitary_dump_station']\n",
    "\n",
    "public_amenities_points = points_of_interest_points[points_of_interest_points['amenity'].isin(public_amenities)]\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(public_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amenity\n",
       "toilets            15662\n",
       "drinking_water      3081\n",
       "waste_disposal       487\n",
       "waste_basket          62\n",
       "shower                60\n",
       "recycling             44\n",
       "vending_machine       16\n",
       "clock                 15\n",
       "fountain              14\n",
       "street_lamp           11\n",
       "telephone              3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_amenities_points['amenity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_amenities_points.drop(['name', 'name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "public_amenities_points = extract_coordinates_from_geometry(public_amenities_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental & Agricultural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agr_env_amenities = [\n",
    "    'grinding_mill', 'compost_site','water_or_irrigation', 'water_point', 'watering_place',\n",
    "    'agriculture', 'green_house', 'gardens', 'farming', 'cattle_breeding', 'pump_house', 'ranger_station', 'animal_shelter'\n",
    "]\n",
    "\n",
    "agr_env_points = points_of_interest_points[points_of_interest_points['amenity'].isin(agr_env_amenities)]\n",
    "\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(agr_env_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 5773\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "agr_env_points.drop(['name', 'name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "agr_env_points = extract_coordinates_from_geometry(agr_env_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food & Beverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_beverage_amenities = [\n",
    "    'restaurant', 'cafe', 'bar', 'pub', 'fast_food', 'food_court', 'ice_cream', 'restaurant;bar', 'restaurant,bar', 'bbq', 'beer_garden', 'catering_service', 'food_outlet'\n",
    "]\n",
    "\n",
    "food_beverage_points = points_of_interest_points[points_of_interest_points['amenity'].isin(food_beverage_amenities)]\n",
    "food_beverage_points.loc[food_beverage_points['amenity'] == 'pub', 'amenity'] = 'bar'\n",
    "food_beverage_points.loc[food_beverage_points['amenity'] == 'beer_garden', 'amenity'] = 'bar'\n",
    "food_beverage_points.loc[food_beverage_points['amenity'] == 'restaurant;bar', 'amenity'] = 'restaurant'\n",
    "food_beverage_points.loc[food_beverage_points['amenity'] == 'restaurant;bar', 'amenity'] = 'restaurant'\n",
    "food_beverage_points.loc[food_beverage_points['amenity'] == 'bbq', 'amenity'] = 'restaurant'\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(food_beverage_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 3491\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "food_beverage_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "food_beverage_points = extract_coordinates_from_geometry(food_beverage_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_services_amenities = [\n",
    "    'police', 'fire_station', 'ambulance_station', 'courthouse', 'townhall', 'public_building', 'public_facility', 'social_centre', 'community_centre', 'social_facility', 'civic_service', 'prison', 'emergency_service', 'rescue_service'\n",
    "]\n",
    "\n",
    "public_services_points = points_of_interest_points[points_of_interest_points['amenity'].isin(public_services_amenities)]\n",
    "public_services_points.loc[public_services_points['amenity'] == 'public_facility', 'amenity'] = 'public_building'\n",
    "public_services_points.loc[public_services_points['amenity'] == 'social_centre', 'amenity'] = 'social_facility'\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(public_services_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_services_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "public_services_points = extract_coordinates_from_geometry(public_services_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_services_points['amenity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leisure & Entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leisure_amenities = [\n",
    "    'cinema', 'theatre', 'nightclub', 'club', 'gaming', 'arts_centre', 'exhibition_centre', 'leisure', 'music_venue', 'dance_club', 'gambling', 'sports_club', 'events_venue', 'studio', 'casino', 'internet_cafe'\n",
    "]\n",
    "\n",
    "leisure_points = points_of_interest_points[points_of_interest_points['amenity'].isin(leisure_amenities)]\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(leisure_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 232\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "leisure_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "leisure_points = extract_coordinates_from_geometry(leisure_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amenity\n",
       "cinema               93\n",
       "nightclub            59\n",
       "studio               29\n",
       "theatre              29\n",
       "arts_centre          11\n",
       "events_venue          7\n",
       "exhibition_centre     2\n",
       "gambling              2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leisure_points['amenity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shopping & Retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_amenities = [\n",
    "    'marketplace', 'shop', 'supermarket', 'butcher', 'butchery', 'shopping_mall', 'vending_machine', 'car_wash', 'bicycle_repair_station', 'hairdresser'\n",
    "]\n",
    "\n",
    "shopping_retail_points = points_of_interest_points[points_of_interest_points['amenity'].isin(shopping_amenities)]\n",
    "shopping_retail_points.loc[shopping_retail_points['amenity'] == 'butchery', 'amenity'] = 'butcher'\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(shopping_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points processed: 1781\n",
      "Number of missing coordinates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n",
      "/var/folders/b7/2dqsctv50sbgk3bg9gpz453c0000gn/T/ipykernel_22851/3776026523.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "shopping_retail_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "shopping_retail_points = extract_coordinates_from_geometry(shopping_retail_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_of_interest_points['amenity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Religious Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "religious_amenities = [\n",
    "    'place_of_worship', 'church', 'mosque', 'monastery'\n",
    "]\n",
    "\n",
    "religious_buildings_points = points_of_interest_points[points_of_interest_points['amenity'].isin(religious_amenities)]\n",
    "\n",
    "points_of_interest_points = points_of_interest_points[~points_of_interest_points['amenity'].isin(religious_amenities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religious_buildings_points.drop(['name:en', 'man_made', 'shop', 'tourism',\n",
    "       'opening_hours', 'beds', 'rooms', 'addr:full', 'addr:housenumber',\n",
    "       'addr:street', 'addr:city', 'source', 'name:sw'], axis = 1, inplace=True)\n",
    "\n",
    "religious_buildings_points = extract_coordinates_from_geometry(religious_buildings_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With the Crimes Data CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_counties = pd.read_csv(\"../data/KEN_county_subcounty_crime_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_counties = gpd.read_file('../data/ken_adm_iebc_20191031_shp/ken_admbnda_adm2_iebc_20191031.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the sub-county names are consistent (e.g., case-insensitive comparison)\n",
    "sub_counties['ADM2_EN'] = sub_counties['ADM2_EN'].str.strip().str.lower()\n",
    "crimes_counties['sub-county'] = crimes_counties['sub-county'].str.strip().str.lower()\n",
    "\n",
    "# Identify sub-counties in df2 that are not in df1\n",
    "unmatched_sub_counties = crimes_counties[~crimes_counties['sub-county'].isin(sub_counties['ADM2_EN'])]\n",
    "\n",
    "# Output the unmatched sub-counties\n",
    "print(\"Sub-counties in df2 that do not match any in df1:\")\n",
    "print(unmatched_sub_counties['sub-county'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subcounty_from_coordinates(df, sub_counties):\n",
    "    geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
    "    h3_gdf = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "    # 2. Perform spatial join\n",
    "    # This will add all columns from counties to your H3 data\n",
    "    result = gpd.sjoin(h3_gdf, sub_counties, how='left', predicate='within')\n",
    "\n",
    "    # 3. If you only want to keep the county name (assuming it's in 'ADM1_EN')\n",
    "    # Keep only the original columns plus the county name\n",
    "    original_columns = list(df.columns)\n",
    "    df['sub_county'] = result['ADM2_EN']\n",
    "\n",
    "    # # 4. Some hexagons are left unmatched so perform other operations to match them with a county\n",
    "    unmatched_hexagons = df[df['sub_county'].isna()].copy()\n",
    "    geometry = [Point(xy) for xy in zip(unmatched_hexagons['longitude'], unmatched_hexagons['latitude'])]\n",
    "    h3_gdf = gpd.GeoDataFrame(unmatched_hexagons, geometry=geometry, crs='EPSG:4326')\n",
    "    intersect_match = gpd.sjoin(h3_gdf, sub_counties, how='left', predicate='intersects')\n",
    "\n",
    "    print(f\"Number of unmatched hexagons = {len(unmatched_hexagons)}\")\n",
    "    print(f\"Number of intersect matches = {len(intersect_match)}\")\n",
    "    \n",
    "    def assign_nearest_county(point, counties_gdf):\n",
    "        # Calculate distance to all counties\n",
    "        distances = counties_gdf.geometry.distance(point.geometry)\n",
    "        # Get the county with minimum distance\n",
    "        nearest_county = counties_gdf.iloc[distances.argmin()]\n",
    "        return nearest_county['ADM2_EN']\n",
    "\n",
    "    # For any hexagons still unmatched after intersects, find nearest county\n",
    "    still_unmatched = intersect_match[intersect_match['sub_county'].isna()]\n",
    "    if len(still_unmatched) > 0:\n",
    "        still_unmatched['nearest_sub_county'] = still_unmatched.apply(\n",
    "            lambda x: assign_nearest_county(x, sub_counties), axis=1\n",
    "        )\n",
    "\n",
    "    df.loc[still_unmatched.index, 'sub_county'] = still_unmatched['nearest_sub_county']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_with_poverty_sub_counties = get_subcounty_from_coordinates(h3_with_poverty.copy(), sub_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_with_poverty_sub_counties['sub_county'] = h3_with_poverty_sub_counties['sub_county'].str.strip().str.lower()\n",
    "crimes_counties['sub-county'] = crimes_counties['sub-county'].str.strip().str.lower()\n",
    "\n",
    "# Add the 'high_crime_in_county' column with default value of 0\n",
    "h3_with_poverty_sub_counties['high_crime_in_county'] = 0\n",
    "\n",
    "# Update 'high_crime_in_county' to 1 for matches in df2\n",
    "h3_with_poverty_sub_counties.loc[h3_with_poverty_sub_counties['sub_county'].isin(crimes_counties['sub-county']), 'high_crime_in_county'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterways_lines = gpd.read_file('../data/ken_waterways_lines/ken_waterways_lines.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterways_lines.drop(['name', 'name:en', 'covered', 'width', 'depth', 'layer',\n",
    "       'blockage', 'tunnel', 'natural', 'water', 'source', 'name:sw'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterways_lines['waterway'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df_info(waterways_lines, 'waterways_lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexagons_dataframe_to_geojson(df_hex, file_output = None, column_name = \"total_population\"):\n",
    "    \"\"\"\n",
    "    Produce the GeoJSON for a dataframe, constructing the geometry from the \"hex_id\" column\n",
    "    and with a property matching the one in column_name\n",
    "    \"\"\"    \n",
    "    list_features = []\n",
    "    \n",
    "    for i,row in df_hex.iterrows():\n",
    "        try:\n",
    "            geometry_for_row = { \"type\" : \"Polygon\", \"coordinates\": [h3.h3_to_geo_boundary(h=row[\"h3\"],geo_json=True)]}\n",
    "            feature = Feature(geometry = geometry_for_row , id=row[\"h3\"], properties = {column_name : row[column_name]})\n",
    "            list_features.append(feature)\n",
    "        except:\n",
    "            print(\"An exception occurred for hex \" + row[\"h3\"]) \n",
    "\n",
    "    feat_collection = FeatureCollection(list_features)\n",
    "    geojson_result = json.dumps(feat_collection)\n",
    "    return geojson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choropleth_map(df_aggreg, border_color = 'black', fill_opacity = 0.7, initial_map = None, with_legend = False,\n",
    "                   kind = \"linear\"):   \n",
    "    #colormap\n",
    "    min_value = df_aggreg[\"total_population\"].min()\n",
    "    max_value = df_aggreg[\"total_population\"].max()\n",
    "    m = round ((min_value + max_value ) / 2 , 0)\n",
    "    \n",
    "    #take resolution from the first row\n",
    "    res = 8\n",
    "    \n",
    "    if initial_map is None:\n",
    "        initial_map = Map(location= [-1.286389, 36.817223], zoom_start=6, tiles=\"cartodbpositron\", \n",
    "                attr= '© <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors © <a href=\"http://cartodb.com/attributions#basemaps\">CartoDB</a>' \n",
    "            )\n",
    "        \n",
    "\n",
    "    #the colormap \n",
    "    #color names accepted https://github.com/python-visualization/branca/blob/master/branca/_cnames.json\n",
    "    if kind == \"linear\":\n",
    "        custom_cm = cm.LinearColormap(['green','yellow','red'], vmin=min_value, vmax=max_value)\n",
    "    elif kind == \"outlier\":\n",
    "        #for outliers, values would be -11,0,1\n",
    "        custom_cm = cm.LinearColormap(['blue','white','red'], vmin=min_value, vmax=max_value)\n",
    "    elif kind == \"filled_nulls\":\n",
    "        custom_cm = cm.LinearColormap(['sienna','green','yellow','red'], \n",
    "                                      index=[0,min_value,m,max_value],vmin=min_value,vmax=max_value)\n",
    "   \n",
    "\n",
    "    #create geojson data from dataframe\n",
    "    geojson_data = hexagons_dataframe_to_geojson(df_hex = df_aggreg)\n",
    "    \n",
    "    #plot on map\n",
    "    name_layer = \"Choropleth \" + str(res)\n",
    "    if kind != \"linear\":\n",
    "        name_layer = name_layer + kind\n",
    "        \n",
    "    GeoJson(\n",
    "        geojson_data,\n",
    "        style_function = lambda feature: {\n",
    "            'fillColor': custom_cm(feature['properties']['total_population']),\n",
    "            'color': border_color,\n",
    "            'weight': 1,\n",
    "            'Highlight': True,\n",
    "            'fillOpacity': fill_opacity \n",
    "        }, \n",
    "        name = name_layer\n",
    "    ).add_to(initial_map)\n",
    "\n",
    "    #add legend (not recommended if multiple layers)\n",
    "    if with_legend == True:\n",
    "        custom_cm.add_to(initial_map)   \n",
    "    \n",
    "    \n",
    "    return initial_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexmap = choropleth_map(df_aggreg = financial_services[financial_services['name'].isna()], with_legend = True, kind = \"filled_nulls\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
